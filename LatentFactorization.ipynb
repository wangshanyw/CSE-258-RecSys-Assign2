{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefab22f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-30T05:41:13.418523Z",
     "iopub.status.busy": "2022-05-30T05:41:13.417919Z",
     "iopub.status.idle": "2022-05-30T05:41:15.111511Z",
     "shell.execute_reply": "2022-05-30T05:41:15.110749Z"
    },
    "papermill": {
     "duration": 1.715527,
     "end_time": "2022-05-30T05:41:15.113618",
     "exception": false,
     "start_time": "2022-05-30T05:41:13.398091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88201589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:41:15.149564Z",
     "iopub.status.busy": "2022-05-30T05:41:15.149333Z",
     "iopub.status.idle": "2022-05-30T05:41:15.203661Z",
     "shell.execute_reply": "2022-05-30T05:41:15.202994Z"
    },
    "papermill": {
     "duration": 0.074055,
     "end_time": "2022-05-30T05:41:15.205263",
     "exception": false,
     "start_time": "2022-05-30T05:41:15.131208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_users = 6611\n",
    "n_items = 79937\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2207fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:41:41.770355Z",
     "iopub.status.busy": "2022-05-30T05:41:41.770077Z",
     "iopub.status.idle": "2022-05-30T05:41:45.695261Z",
     "shell.execute_reply": "2022-05-30T05:41:45.694450Z"
    },
    "papermill": {
     "duration": 3.984828,
     "end_time": "2022-05-30T05:41:45.697506",
     "exception": false,
     "start_time": "2022-05-30T05:41:41.712678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# to do: str_id -> int\n",
    "cite_file = 'data/paper_file_ann.txt'\n",
    "coauthor_file = 'data/author_file_ann.txt'\n",
    "author_train_file = 'data/bipartite_train_ann.txt'\n",
    "author_test_file = 'data/bipartite_test_ann.txt'\n",
    "\n",
    "import random as rd\n",
    "\n",
    "def generate_test(all_user_ratings):\n",
    "    ratings_test = {}\n",
    "    for user in all_user_ratings:\n",
    "        ratings_test[user] = rd.sample(all_user_ratings[user], 1)[0]\n",
    "    return ratings_test\n",
    "\n",
    "def load_data(cite_file, coauthor_file, author_train_file, author_test_file, n_users):\n",
    "    citation, author_train, coauthor = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "    user_ratings_train = defaultdict(list)\n",
    "    test_ratings = defaultdict(list)\n",
    "    \n",
    "    train_users = set()\n",
    "\n",
    "    with open(cite_file, 'r') as f:\n",
    "        line = f.readlines()\n",
    "    for l in line:\n",
    "        src, tgt = l.strip().split(' ')\n",
    "        src, tgt = int(src), int(tgt)\n",
    "        citation['src'].append(src)\n",
    "        citation['tgt'].append(tgt)\n",
    "\n",
    "    with open(coauthor_file, 'r') as f:\n",
    "        line = f.readlines()\n",
    "    for l in line:\n",
    "        src, tgt = l.strip().split(' ')\n",
    "        src, tgt = int(src), int(tgt)\n",
    "        coauthor['src'].append(src)\n",
    "        coauthor['tgt'].append(tgt)\n",
    "    \n",
    "    with open(author_train_file, 'r') as f:\n",
    "        line = f.readlines()\n",
    "        train_interacts = len(line)\n",
    "    for l in line:\n",
    "        src, tgt = l.strip().split(' ')\n",
    "        src, tgt = int(src), int(tgt)\n",
    "        user_ratings_train[src].append(tgt)\n",
    "        author_train['src'].append(src)\n",
    "        author_train['tgt'].append(tgt+n_users)\n",
    "        train_users.add(src)\n",
    "    \n",
    "    with open(author_test_file, 'r') as f:\n",
    "        line = f.readlines()\n",
    "    for l in line:\n",
    "        src, tgt = l.strip().split(' ')\n",
    "        src, tgt = int(src), int(tgt)\n",
    "        test_ratings[src].append(tgt)\n",
    "        \n",
    "    user_ratings_test = generate_test(user_ratings_train)\n",
    "            \n",
    "    return citation, author_train, coauthor, user_ratings_train, user_ratings_test, train_interacts, list(train_users), test_ratings\n",
    "\n",
    "citation, author_train, coauthor, user_ratings_train, user_ratings_test, train_interacts, train_users, test_ratings = \\\n",
    "            load_data(cite_file, coauthor_file, author_train_file, author_test_file, n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af3819a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:41:45.813335Z",
     "iopub.status.busy": "2022-05-30T05:41:45.811780Z",
     "iopub.status.idle": "2022-05-30T05:41:48.556646Z",
     "shell.execute_reply": "2022-05-30T05:41:48.555445Z"
    },
    "papermill": {
     "duration": 2.804174,
     "end_time": "2022-05-30T05:41:48.559619",
     "exception": false,
     "start_time": "2022-05-30T05:41:45.755445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79937, 512])\n"
     ]
    }
   ],
   "source": [
    "# load pickle \n",
    "feature_file = 'data/feature.pkl'\n",
    "\n",
    "def load_item_feature(feature_file):\n",
    "    with open(feature_file, 'rb') as f:\n",
    "        feature_matrix = pickle.load(f)\n",
    "    # feature_matrix_shape: 79937*512\n",
    "    print(feature_matrix.shape)\n",
    "    return feature_matrix\n",
    "# torch.Size([79937, 512])\n",
    "item_feature = load_item_feature(feature_file)\n",
    "item_feature_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LatentFactorizationModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_factors):\n",
    "        super(LatentFactorizationModel, self).__init__()\n",
    "        self.user_factors = nn.Embedding(num_users, num_factors)\n",
    "        self.item_factors = nn.Embedding(num_items, num_factors)\n",
    "        self.item_factors.weight.data = item_feature.clone().detach()\n",
    "        \n",
    "        self.user_biases = nn.Embedding(num_users, 1)\n",
    "        self.item_biases = nn.Embedding(num_items, 1)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.user_factors(user_indices)\n",
    "        item_embedding = self.item_factors(item_indices)\n",
    "\n",
    "        interaction = torch.sum(user_embedding * item_embedding, dim=1)\n",
    "\n",
    "        user_bias = self.user_biases(user_indices).squeeze()\n",
    "        item_bias = self.item_biases(item_indices).squeeze()\n",
    "        prediction = interaction + user_bias + item_bias\n",
    "        # print(prediction.shape)\n",
    "        prediction = torch.sigmoid(prediction)\n",
    "        return prediction\n",
    "\n",
    "    def loss(self, predictions, ratings):\n",
    "        return F.mse_loss(predictions, ratings)\n",
    "\n",
    "    def predict(self, users, items):\n",
    "        user_embedding = self.user_factors(users)\n",
    "        item_embedding = self.item_factors(items)\n",
    "\n",
    "        interaction = torch.sum(user_embedding * item_embedding, dim=1)\n",
    "\n",
    "        user_bias = self.user_biases(users).squeeze()\n",
    "        item_bias = self.item_biases(items).squeeze()\n",
    "        prediction = interaction + user_bias + item_bias\n",
    "        prediction = torch.sigmoid(prediction)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e8f6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:43:07.528538Z",
     "iopub.status.busy": "2022-05-30T05:43:07.528319Z",
     "iopub.status.idle": "2022-05-30T05:43:07.536964Z",
     "shell.execute_reply": "2022-05-30T05:43:07.536333Z"
    },
    "papermill": {
     "duration": 0.066298,
     "end_time": "2022-05-30T05:43:07.538641",
     "exception": false,
     "start_time": "2022-05-30T05:43:07.472343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_train_batch(user_ratings_train, n, batch_size, train_users, test_ratings):\n",
    "    t = []\n",
    "    user_pos_neg = []\n",
    "    for b in range(batch_size):\n",
    "        u = rd.sample(train_users, 1)[0]\n",
    "        i = rd.sample(user_ratings_train[u], 1)[0]\n",
    "        j = rd.randint(0, n - 1)\n",
    "        # one negative sample\n",
    "        while j in user_ratings_train[u] and j in test_ratings[u]:\n",
    "            j = rd.randint(0, n - 1)\n",
    "        t.append([u, i, 1])\n",
    "        t.append([u, j, 0])\n",
    "        user_pos_neg.append([u, i, j])\n",
    "    train_batch = np.asarray(t)\n",
    "    user_pos_neg = np.asarray(user_pos_neg)\n",
    "    return train_batch, user_pos_neg\n",
    "\n",
    "def generate_test_batch(user_ratings, user_ratings_test, n, train_users, test_ratings):\n",
    "    t = []\n",
    "    for u in train_users:\n",
    "        i = user_ratings_test[u]\n",
    "        rated = user_ratings[u]\n",
    "        for j in range(10):\n",
    "            k = np.random.randint(0, n)\n",
    "            while k in rated and k in test_ratings[u]:\n",
    "                k = np.random.randint(0, n)\n",
    "            t.append([u, i, 1])\n",
    "            t.append([u, k, 0])\n",
    "    test_batch = np.asarray(t)\n",
    "    return test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e35a51f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:43:07.650658Z",
     "iopub.status.busy": "2022-05-30T05:43:07.650059Z",
     "iopub.status.idle": "2022-05-30T05:43:08.504866Z",
     "shell.execute_reply": "2022-05-30T05:43:08.504136Z"
    },
    "papermill": {
     "duration": 0.913651,
     "end_time": "2022-05-30T05:43:08.507710",
     "exception": false,
     "start_time": "2022-05-30T05:43:07.594059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluation(pred, labels):\n",
    "    auc = cal_auc(pred, labels)\n",
    "    pred = (pred > 0.5).astype(int)\n",
    "    labels = (labels > 0.5).astype(int)\n",
    "    precision = precision_score(pred, labels, average='binary')\n",
    "    recall = recall_score(pred, labels, average='binary')\n",
    "    f1score = f1_score(pred, labels, average='binary')\n",
    "    return auc, precision, recall, f1score\n",
    "\n",
    "def cal_auc(pred, labels):\n",
    "    P_ind = []  # 正样本下标\n",
    "    F_ind = []  # 负样本下标\n",
    "\n",
    "    #  计数过程\n",
    "    for ind, val in enumerate(labels):\n",
    "        if val > 0.5:\n",
    "            P_ind.append(ind)\n",
    "        else:\n",
    "            F_ind.append(ind)\n",
    "\n",
    "    new_data = [[p, l] for p, l in zip(pred, labels)]\n",
    "    new_data.sort(key=lambda x:x[0])\n",
    "\n",
    "    # 求正样本rank之和\n",
    "    rank_sum = 0\n",
    "    for ind, [prob, label] in enumerate(new_data):\n",
    "        if label>0.5:\n",
    "            rank_sum+=ind\n",
    "    auc = (rank_sum - len(P_ind)*(1+len(P_ind))/2) / (len(P_ind)*len(F_ind))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c48182c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:43:09.826021Z",
     "iopub.status.busy": "2022-05-30T05:43:09.825740Z",
     "iopub.status.idle": "2022-05-30T05:43:09.829595Z",
     "shell.execute_reply": "2022-05-30T05:43:09.828943Z"
    },
    "papermill": {
     "duration": 0.062913,
     "end_time": "2022-05-30T05:43:09.831285",
     "exception": false,
     "start_time": "2022-05-30T05:43:09.768372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params\n",
    "batch_size = 65536\n",
    "# emb_dim = 64\n",
    "lr = 0.0005\n",
    "num_epoches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1f3b32f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:43:14.185157Z",
     "iopub.status.busy": "2022-05-30T05:43:14.184898Z",
     "iopub.status.idle": "2022-05-30T13:22:37.718887Z",
     "shell.execute_reply": "2022-05-30T13:22:37.718153Z"
    },
    "papermill": {
     "duration": 27563.594498,
     "end_time": "2022-05-30T13:22:37.720891",
     "exception": false,
     "start_time": "2022-05-30T05:43:14.126393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 393216/2752512 [01:21<08:06, 4852.75it/s]  \n",
      "100%|██████████| 2752512/2752512 [00:17<00:00, 162174.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 0.329619\n",
      "Evaluation: auc:0.5090032503289859, precision:0.5143852210781344, recall:0.507249622959877, f1:0.510792502762971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 150027.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 0.320518\n",
      "Evaluation: auc:0.5175242983622061, precision:0.5248334342822532, recall:0.5133902121104397, f1:0.519048760033545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 145751.75it/s]\n",
      "100%|██████████| 2752512/2752512 [00:17<00:00, 154719.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 0.313353\n",
      "Evaluation: auc:0.5217536056373888, precision:0.5345245305875227, recall:0.5174966648586047, f1:0.5258727924143223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 144258.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.307805\n",
      "Evaluation: auc:0.5283427651174829, precision:0.5469412477286493, recall:0.525022893440121, f1:0.5357579892759405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142759.50it/s]\n",
      "100%|██████████| 2752512/2752512 [00:17<00:00, 152173.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.303566\n",
      "Evaluation: auc:0.5321726920820705, precision:0.5560266505148395, recall:0.52766960295449, f1:0.5414771177255602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 145064.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.300016\n",
      "Evaluation: auc:0.534914475598182, precision:0.5596608116293156, recall:0.5295204802361065, f1:0.5441736172969472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142371.34it/s]\n",
      "100%|██████████| 2752512/2752512 [00:17<00:00, 153025.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.297362\n",
      "Evaluation: auc:0.5392658249813541, precision:0.5675348273773471, recall:0.5341542320464036, f1:0.5503388225274765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 144797.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.295386\n",
      "Evaluation: auc:0.5407238454861525, precision:0.5716232586311326, recall:0.5356433395765935, f1:0.5530487268891559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 144572.57it/s]\n",
      "100%|██████████| 2752512/2752512 [00:16<00:00, 165331.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.293410\n",
      "Evaluation: auc:0.5434759865081861, precision:0.5755602665051484, recall:0.5358728905556104, f1:0.5550079943929737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:17<00:00, 153355.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.292165\n",
      "Evaluation: auc:0.5458823846641776, precision:0.5773773470623864, recall:0.5382172348083845, f1:0.5571099828323045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 147031.14it/s]\n",
      "100%|██████████| 2752512/2752512 [00:17<00:00, 160827.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.290887\n",
      "Evaluation: auc:0.5446493457336027, precision:0.5790430042398547, recall:0.5383413343094055, f1:0.5579508728925463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:17<00:00, 154549.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.290161\n",
      "Evaluation: auc:0.5463627595154599, precision:0.5820714718352513, recall:0.540563344630226, f1:0.5605500506740745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 143335.08it/s]\n",
      "100%|██████████| 2752512/2752512 [07:37<00:00, 134986.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.289157\n",
      "Evaluation: auc:0.5490499696236079, precision:0.5841913991520291, recall:0.5419300463548251, f1:0.5622677257159513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [07:38<00:00, 6003.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.288547\n",
      "Evaluation: auc:0.5484480456386949, precision:0.5811629315566323, recall:0.5406852248394004, f1:0.5601938346567025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 143408.64it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 148444.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.287700\n",
      "Evaluation: auc:0.5476251797178151, precision:0.5835857056329498, recall:0.5404495800086944, f1:0.5611899440120567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 146115.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.287100\n",
      "Evaluation: auc:0.5479603541307674, precision:0.5858570563294972, recall:0.5416643333146666, f1:0.5628946372974074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 144765.06it/s]\n",
      "100%|██████████| 2752512/2752512 [00:17<00:00, 153886.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.286508\n",
      "Evaluation: auc:0.5474690237842014, precision:0.5847970926711085, recall:0.5407978939408791, f1:0.5619375350119677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 147158.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.286222\n",
      "Evaluation: auc:0.5476188347938826, precision:0.5866141732283464, recall:0.5413790212135611, f1:0.563089579790404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 145102.10it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 142919.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.285640\n",
      "Evaluation: auc:0.547759486569269, precision:0.5852513628104179, recall:0.5408166120952621, f1:0.562157287681992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 143088.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.284912\n",
      "Evaluation: auc:0.548850863012377, precision:0.5844942459115687, recall:0.5431341372469008, f1:0.5630556710354535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "########################### START TRAINING & TESTING & EVALUATION#####################################\n",
    "model = LatentFactorizationModel(n_users, n_items, item_feature_dim).to(device)\n",
    "opt = torch.optim.Adam(lr=lr, params=model.parameters(), weight_decay=0.001)\n",
    "\n",
    "all_loss = []\n",
    "performance = []\n",
    "best_auc = 0\n",
    "best_precision = 0\n",
    "model_save_path = 'model/'\n",
    "pre_loss = 0\n",
    "for epoch in range(1, num_epoches+1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    n_batches = train_interacts // batch_size + 1\n",
    "    pbar = tqdm(total=n_batches*batch_size*2)\n",
    "    for i in range(n_batches):\n",
    "        uij, _  = generate_train_batch(user_ratings_train, n_items, batch_size, train_users, test_ratings)\n",
    "        users, items, labels = uij[:, 0], uij[:, 1], uij[:, 2]\n",
    "        users, items, labels = torch.tensor(users).to(device), torch.tensor(items).to(device), torch.tensor(labels).float().to(device)\n",
    "        predictions = model(users, items).float()\n",
    "        loss = model.loss(predictions, labels)\n",
    "        train_loss += loss.item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        pbar.update(batch_size*2)\n",
    "    train_loss /= n_batches\n",
    "    all_loss.append(train_loss)\n",
    "    print(\"epoch {}, train loss: {:4f}\".format(epoch, train_loss))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_uij = generate_test_batch(user_ratings_train, user_ratings_test, n_items, train_users, test_ratings)\n",
    "        users, items, labels = t_uij[:, 0], t_uij[:, 1], t_uij[:, 2]\n",
    "        users, items = torch.tensor(users).to(device), torch.tensor(items).to(device)\n",
    "        pred = model.predict(users, items)\n",
    "        pred = pred.cpu().numpy()\n",
    "        auc, precision, recall, f1score = evaluation(pred, labels)\n",
    "        performance.append([auc, precision, recall, f1score])\n",
    "        print(\"Evaluation: auc:{}, precision:{}, recall:{}, f1:{}\".format(auc, precision, recall, f1score)) \n",
    "        if auc > best_auc and train_loss < pre_loss:\n",
    "            best_auc = auc\n",
    "            best_precision = precision\n",
    "            state = {'net': model.state_dict(), 'opt':opt.state_dict(), 'epoch':epoch}\n",
    "            torch.save(state, model_save_path+f\"model_{epoch}.pth\")\n",
    "        pre_loss = train_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27727.746636,
   "end_time": "2022-05-30T13:23:12.996049",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-30T05:41:05.249413",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
