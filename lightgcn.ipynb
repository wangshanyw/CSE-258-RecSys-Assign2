{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefab22f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-30T05:41:13.418523Z",
     "iopub.status.busy": "2022-05-30T05:41:13.417919Z",
     "iopub.status.idle": "2022-05-30T05:41:15.111511Z",
     "shell.execute_reply": "2022-05-30T05:41:15.110749Z"
    },
    "papermill": {
     "duration": 1.715527,
     "end_time": "2022-05-30T05:41:15.113618",
     "exception": false,
     "start_time": "2022-05-30T05:41:13.398091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88201589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:41:15.149564Z",
     "iopub.status.busy": "2022-05-30T05:41:15.149333Z",
     "iopub.status.idle": "2022-05-30T05:41:15.203661Z",
     "shell.execute_reply": "2022-05-30T05:41:15.202994Z"
    },
    "papermill": {
     "duration": 0.074055,
     "end_time": "2022-05-30T05:41:15.205263",
     "exception": false,
     "start_time": "2022-05-30T05:41:15.131208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_users = 6611\n",
    "n_items = 79937\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2207fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:41:41.770355Z",
     "iopub.status.busy": "2022-05-30T05:41:41.770077Z",
     "iopub.status.idle": "2022-05-30T05:41:45.695261Z",
     "shell.execute_reply": "2022-05-30T05:41:45.694450Z"
    },
    "papermill": {
     "duration": 3.984828,
     "end_time": "2022-05-30T05:41:45.697506",
     "exception": false,
     "start_time": "2022-05-30T05:41:41.712678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# to do: str_id -> int\n",
    "cite_file = 'data/paper_file_ann.txt'\n",
    "coauthor_file = 'data/author_file_ann.txt'\n",
    "author_train_file = 'data/bipartite_train_ann.txt'\n",
    "author_test_file = 'data/bipartite_test_ann.txt'\n",
    "\n",
    "import random as rd\n",
    "\n",
    "def generate_test(all_user_ratings):\n",
    "    ratings_test = {}\n",
    "    for user in all_user_ratings:\n",
    "        ratings_test[user] = rd.sample(all_user_ratings[user], 1)[0]\n",
    "    return ratings_test\n",
    "\n",
    "def load_data(cite_file, coauthor_file, author_train_file, author_test_file, n_users):\n",
    "    citation, author_train, coauthor = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "    user_ratings_train = defaultdict(list)\n",
    "    test_ratings = defaultdict(list)\n",
    "    \n",
    "    train_users = set()\n",
    "\n",
    "    with open(cite_file, 'r') as f:\n",
    "        line = f.readlines()\n",
    "    for l in line:\n",
    "        src, tgt = l.strip().split(' ')\n",
    "        src, tgt = int(src), int(tgt)\n",
    "        citation['src'].append(src)\n",
    "        citation['tgt'].append(tgt)\n",
    "\n",
    "    with open(coauthor_file, 'r') as f:\n",
    "        line = f.readlines()\n",
    "    for l in line:\n",
    "        src, tgt = l.strip().split(' ')\n",
    "        src, tgt = int(src), int(tgt)\n",
    "        coauthor['src'].append(src)\n",
    "        coauthor['tgt'].append(tgt)\n",
    "    \n",
    "    with open(author_train_file, 'r') as f:\n",
    "        line = f.readlines()\n",
    "        train_interacts = len(line)\n",
    "    for l in line:\n",
    "        src, tgt = l.strip().split(' ')\n",
    "        src, tgt = int(src), int(tgt)\n",
    "        user_ratings_train[src].append(tgt)\n",
    "        author_train['src'].append(src)\n",
    "        author_train['tgt'].append(tgt+n_users)\n",
    "        train_users.add(src)\n",
    "    \n",
    "    with open(author_test_file, 'r') as f:\n",
    "        line = f.readlines()\n",
    "    for l in line:\n",
    "        src, tgt = l.strip().split(' ')\n",
    "        src, tgt = int(src), int(tgt)\n",
    "        test_ratings[src].append(tgt)\n",
    "        \n",
    "    user_ratings_test = generate_test(user_ratings_train)\n",
    "            \n",
    "    return citation, author_train, coauthor, user_ratings_train, user_ratings_test, train_interacts, list(train_users), test_ratings\n",
    "\n",
    "citation, author_train, coauthor, user_ratings_train, user_ratings_test, train_interacts, train_users, test_ratings = \\\n",
    "            load_data(cite_file, coauthor_file, author_train_file, author_test_file, n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af3819a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:41:45.813335Z",
     "iopub.status.busy": "2022-05-30T05:41:45.811780Z",
     "iopub.status.idle": "2022-05-30T05:41:48.556646Z",
     "shell.execute_reply": "2022-05-30T05:41:48.555445Z"
    },
    "papermill": {
     "duration": 2.804174,
     "end_time": "2022-05-30T05:41:48.559619",
     "exception": false,
     "start_time": "2022-05-30T05:41:45.755445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79937, 512])\n"
     ]
    }
   ],
   "source": [
    "# load pickle \n",
    "feature_file = 'data/feature.pkl'\n",
    "\n",
    "def load_item_feature(feature_file):\n",
    "    with open(feature_file, 'rb') as f:\n",
    "        feature_matrix = pickle.load(f)\n",
    "    # feature_matrix_shape: 79937*512\n",
    "    print(feature_matrix.shape)\n",
    "    return feature_matrix\n",
    "# torch.Size([79937, 512])\n",
    "item_feature = load_item_feature(feature_file)\n",
    "item_feature_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate single-normalized adjacency matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roxanne\\AppData\\Local\\Temp\\ipykernel_31280\\3480713632.py:8: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate single-normalized adjacency matrix.\n",
      "already normalize adjacency matrix\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def create_adj_mat(adj_mat):    \n",
    "    def mean_adj_single(adj):\n",
    "        # D^-1 * A\n",
    "        rowsum = np.array(adj.sum(1))\n",
    "\n",
    "        d_inv = np.power(rowsum, -1).flatten()\n",
    "        d_inv[np.isinf(d_inv)] = 0.\n",
    "        d_mat_inv = sp.diags(d_inv)\n",
    "\n",
    "        norm_adj = d_mat_inv.dot(adj)\n",
    "        # norm_adj = adj.dot(d_mat_inv)\n",
    "        print('generate single-normalized adjacency matrix.')\n",
    "        return norm_adj.tocoo()\n",
    "\n",
    "    def normalized_adj_single(adj):\n",
    "        # D^-1/2 * A * D^-1/2\n",
    "        rowsum = np.array(adj.sum(1))\n",
    "\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "\n",
    "        # bi_lap = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt)\n",
    "        bi_lap = d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt)\n",
    "        return bi_lap.tocoo()\n",
    "\n",
    "    def check_adj_if_equal(adj):\n",
    "        dense_A = np.array(adj.todense())\n",
    "        degree = np.sum(dense_A, axis=1, keepdims=False)\n",
    "\n",
    "        temp = np.dot(np.diag(np.power(degree, -1)), dense_A)\n",
    "        print('check normalized adjacency matrix whether equal to this laplacian matrix.')\n",
    "        return temp\n",
    "\n",
    "    norm_adj_mat = mean_adj_single(adj_mat + sp.eye(adj_mat.shape[0]))\n",
    "    # norm_adj_mat = normalized_adj_single(adj_mat + sp.eye(adj_mat.shape[0]))\n",
    "    mean_adj_mat = mean_adj_single(adj_mat)\n",
    "\n",
    "    print('already normalize adjacency matrix')\n",
    "    return adj_mat.tocsr(), norm_adj_mat.tocsr(), mean_adj_mat.tocsr()\n",
    "\n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "# info graph          \n",
    "R = sp.dok_matrix((n_users, n_items), dtype=np.float32)\n",
    "for user in train_users:\n",
    "    for item in user_ratings_train[user]:\n",
    "        R[user, item] = 1\n",
    "\n",
    "          \n",
    "adj_mat = sp.dok_matrix((n_users + n_items, n_users + n_items), dtype=np.float32)\n",
    "adj_mat = adj_mat.tolil()\n",
    "R = R.tolil()\n",
    "\n",
    "adj_mat[:n_users, n_users:] = R\n",
    "adj_mat[n_users:, :n_users] = R.T\n",
    "adj_mat = adj_mat.todok()\n",
    "\n",
    "_, info_norm_adj, _ = create_adj_mat(adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.sparse as sparse\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, num_layers, graph, keep_prob=0.6):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.n_users = num_users\n",
    "        self.n_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers = num_layers\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        # self.item_embedding.weight.data = item_feature.clone().detach()\n",
    "        \n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.1)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.1)\n",
    "\n",
    "        self.graph = graph\n",
    "        self.graph = self._convert_sp_mat_to_sp_tensor(self.graph)\n",
    "        self.graph = self.graph.coalesce().to(device)\n",
    "    \n",
    "        self.keep_prob = keep_prob\n",
    "    \n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        row = torch.Tensor(coo.row).long()\n",
    "        col = torch.Tensor(coo.col).long()\n",
    "        index = torch.stack([row, col])\n",
    "        data = torch.FloatTensor(coo.data)\n",
    "        return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n",
    "    \n",
    "    def __dropout_x(self, x, keep_prob):\n",
    "        size = x.size()\n",
    "        index = x.indices().t()\n",
    "        values = x.values()\n",
    "        random_index = torch.rand(len(values)) + keep_prob\n",
    "        random_index = random_index.int().bool()\n",
    "        index = index[random_index]\n",
    "        values = values[random_index]/keep_prob\n",
    "        g = torch.sparse.FloatTensor(index.t(), values, size)\n",
    "        return g\n",
    "    \n",
    "    def __dropout(self, keep_prob):\n",
    "        graph = self.__dropout_x(self.graph, keep_prob)\n",
    "        return graph\n",
    "    \n",
    "    def forward(self, users, items):\n",
    "        user_embedding = self.user_embedding.weight\n",
    "        item_embedding = self.item_embedding.weight\n",
    "        all_emb = torch.cat([user_embedding, item_embedding])\n",
    "        embs = [all_emb]\n",
    "        if self.training:\n",
    "            g_droped = self.__dropout(self.keep_prob)\n",
    "        else:\n",
    "            g_droped = self.graph\n",
    "        for layer in range(self.n_layers):\n",
    "            all_emb = torch.sparse.mm(g_droped, all_emb)\n",
    "            embs.append(all_emb)\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        light_out = torch.mean(embs, dim=1)\n",
    "        users_embeddings, items_embeddings = torch.split(light_out, [self.n_users, self.n_items])\n",
    "        items_emb = torch.index_select(item_embedding, 0, items)\n",
    "        users_emb = torch.index_select(user_embedding, 0, users)\n",
    "        # users_emb = users_embeddings[users]\n",
    "        # items_emb = items_embeddings[items]\n",
    "        scores = torch.mul(users_emb, items_emb).sum(dim=1)\n",
    "        scores = torch.sigmoid(scores)\n",
    "        return scores\n",
    "\n",
    "    def loss(self, predictions, ratings):\n",
    "        return F.mse_loss(predictions, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e8f6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:43:07.528538Z",
     "iopub.status.busy": "2022-05-30T05:43:07.528319Z",
     "iopub.status.idle": "2022-05-30T05:43:07.536964Z",
     "shell.execute_reply": "2022-05-30T05:43:07.536333Z"
    },
    "papermill": {
     "duration": 0.066298,
     "end_time": "2022-05-30T05:43:07.538641",
     "exception": false,
     "start_time": "2022-05-30T05:43:07.472343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_train_batch(user_ratings_train, n, batch_size, train_users, test_ratings):\n",
    "    t = []\n",
    "    user_pos_neg = []\n",
    "    for b in range(batch_size):\n",
    "        u = rd.sample(train_users, 1)[0]\n",
    "        i = rd.sample(user_ratings_train[u], 1)[0]\n",
    "        j = rd.randint(0, n - 1)\n",
    "        # one negative sample\n",
    "        while j in user_ratings_train[u] and j in test_ratings[u]:\n",
    "            j = rd.randint(0, n - 1)\n",
    "        t.append([u, i, 1])\n",
    "        t.append([u, j, 0])\n",
    "        user_pos_neg.append([u, i, j])\n",
    "    train_batch = np.asarray(t)\n",
    "    user_pos_neg = np.asarray(user_pos_neg)\n",
    "    return train_batch, user_pos_neg\n",
    "\n",
    "def generate_test_batch(user_ratings, user_ratings_test, n, train_users, test_ratings):\n",
    "    t = []\n",
    "    for u in train_users:\n",
    "        i = user_ratings_test[u]\n",
    "        rated = user_ratings[u]\n",
    "        for j in range(10):\n",
    "            k = np.random.randint(0, n)\n",
    "            while k in rated and k in test_ratings[u]:\n",
    "                k = np.random.randint(0, n)\n",
    "            t.append([u, i, 1])\n",
    "            t.append([u, k, 0])\n",
    "    test_batch = np.asarray(t)\n",
    "    return test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e35a51f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:43:07.650658Z",
     "iopub.status.busy": "2022-05-30T05:43:07.650059Z",
     "iopub.status.idle": "2022-05-30T05:43:08.504866Z",
     "shell.execute_reply": "2022-05-30T05:43:08.504136Z"
    },
    "papermill": {
     "duration": 0.913651,
     "end_time": "2022-05-30T05:43:08.507710",
     "exception": false,
     "start_time": "2022-05-30T05:43:07.594059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluation(pred, labels):\n",
    "    auc = cal_auc(pred, labels)\n",
    "    pred = (pred > 0.5).astype(int)\n",
    "    labels = (labels > 0.5).astype(int)\n",
    "    precision = precision_score(pred, labels, average='binary')\n",
    "    recall = recall_score(pred, labels, average='binary')\n",
    "    f1score = f1_score(pred, labels, average='binary')\n",
    "    return auc, precision, recall, f1score\n",
    "\n",
    "def cal_auc(pred, labels):\n",
    "    P_ind = []  # 正样本下标\n",
    "    F_ind = []  # 负样本下标\n",
    "\n",
    "    #  计数过程\n",
    "    for ind, val in enumerate(labels):\n",
    "        if val > 0.5:\n",
    "            P_ind.append(ind)\n",
    "        else:\n",
    "            F_ind.append(ind)\n",
    "\n",
    "    new_data = [[p, l] for p, l in zip(pred, labels)]\n",
    "    new_data.sort(key=lambda x:x[0])\n",
    "\n",
    "    # 求正样本rank之和\n",
    "    rank_sum = 0\n",
    "    for ind, [prob, label] in enumerate(new_data):\n",
    "        if label>0.5:\n",
    "            rank_sum+=ind\n",
    "    auc = (rank_sum - len(P_ind)*(1+len(P_ind))/2) / (len(P_ind)*len(F_ind))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c48182c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:43:09.826021Z",
     "iopub.status.busy": "2022-05-30T05:43:09.825740Z",
     "iopub.status.idle": "2022-05-30T05:43:09.829595Z",
     "shell.execute_reply": "2022-05-30T05:43:09.828943Z"
    },
    "papermill": {
     "duration": 0.062913,
     "end_time": "2022-05-30T05:43:09.831285",
     "exception": false,
     "start_time": "2022-05-30T05:43:09.768372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params\n",
    "batch_size = 65536\n",
    "# emb_dim = 64\n",
    "lr = 0.001\n",
    "num_epoches = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f3b32f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T05:43:14.185157Z",
     "iopub.status.busy": "2022-05-30T05:43:14.184898Z",
     "iopub.status.idle": "2022-05-30T13:22:37.718887Z",
     "shell.execute_reply": "2022-05-30T13:22:37.718153Z"
    },
    "papermill": {
     "duration": 27563.594498,
     "end_time": "2022-05-30T13:22:37.720891",
     "exception": false,
     "start_time": "2022-05-30T05:43:14.126393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:20<00:00, 136716.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 0.250575\n",
      "Evaluation: auc:0.4959705216008065, precision:0.49772864930345245, recall:0.49719411293128224, f1:0.4974612375237417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:21<00:00, 130049.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 0.250279\n",
      "Evaluation: auc:0.49725144897775003, precision:0.5012113870381587, recall:0.5008700915487629, f1:0.5010406811731315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:20<00:00, 135356.18it/s]\n",
      "100%|██████████| 2752512/2752512 [00:19<00:00, 144412.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 0.250133\n",
      "Evaluation: auc:0.49853810632177475, precision:0.5025741974560872, recall:0.5010945874537631, f1:0.5018333018333019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:20<00:00, 136289.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.250057\n",
      "Evaluation: auc:0.4984744484281868, precision:0.5016656571774682, recall:0.5005060958107352, f1:0.5010852056597068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:20<00:00, 134217.29it/s]\n",
      "100%|██████████| 2752512/2752512 [00:19<00:00, 149399.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.250023\n",
      "Evaluation: auc:0.5002043160891055, precision:0.49939430648092065, recall:0.4991297767688233, f1:0.49926200658517206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:20<00:00, 135196.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.250002\n",
      "Evaluation: auc:0.5006940503452013, precision:0.49818291944276194, recall:0.4992033988316516, f1:0.49869263708363326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 139389.46it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 153223.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.249993\n",
      "Evaluation: auc:0.5018966401986058, precision:0.4974258025439128, recall:0.500030443253775, f1:0.49872472217161595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 139756.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.249991\n",
      "Evaluation: auc:0.5039348507099382, precision:0.5003028467595396, recall:0.5014722399295753, f1:0.500886860815912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142541.62it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 153145.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.249993\n",
      "Evaluation: auc:0.5043090657113267, precision:0.5013628104179285, recall:0.5011806732865101, f1:0.5012717253073337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 140467.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.249994\n",
      "Evaluation: auc:0.503715156572325, precision:0.5043912780133253, recall:0.50271657108361, f1:0.5035525321239607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 141525.27it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 144506.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.249995\n",
      "Evaluation: auc:0.503995595698292, precision:0.5040884312537856, recall:0.5013705232085304, f1:0.5027258037723312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142641.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.249996\n",
      "Evaluation: auc:0.505904888599718, precision:0.5066626287098728, recall:0.5031730277602334, f1:0.5049117988803212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 143827.26it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 154714.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.249997\n",
      "Evaluation: auc:0.5066531977664547, precision:0.5105996365838885, recall:0.5046393295420533, f1:0.5076019870540418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 144093.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.249998\n",
      "Evaluation: auc:0.5080290589353368, precision:0.5169594185342217, recall:0.5077636980189184, f1:0.512320297728023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 146187.73it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 158000.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.249998\n",
      "Evaluation: auc:0.5125648545601825, precision:0.523167777104785, recall:0.5127329929953698, f1:0.5178978294759563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142928.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.249999\n",
      "Evaluation: auc:0.5152881480984856, precision:0.529678982434888, recall:0.5156173995076724, f1:0.5225536110426424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 143622.19it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 155008.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.249999\n",
      "Evaluation: auc:0.5175756252474043, precision:0.5420956995760146, recall:0.5204471775190079, f1:0.53105090226735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 144505.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.249999\n",
      "Evaluation: auc:0.5217135332421552, precision:0.5519382192610539, recall:0.5255417621869458, f1:0.5384166562036087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142872.58it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 157618.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.250000\n",
      "Evaluation: auc:0.5275412660810529, precision:0.5649606299212598, recall:0.5327412399691578, f1:0.5483780883930801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 143402.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.250000\n",
      "Evaluation: auc:0.53383958421763, precision:0.5772259236826166, recall:0.5387224420576597, f1:0.5573099415204679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:18<00:00, 145601.55it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 148418.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.250000\n",
      "Evaluation: auc:0.5432780550102521, precision:0.5858570563294972, recall:0.5462066239376571, f1:0.5653374636527025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142767.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.250000\n",
      "Evaluation: auc:0.5524727171939551, precision:0.594488188976378, recall:0.5556105914153493, f1:0.5743922868157512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142445.99it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 153963.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.250000\n",
      "Evaluation: auc:0.5596831857864899, precision:0.5967595396729255, recall:0.5647183572871738, f1:0.5802969954427324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 144837.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.250000\n",
      "Evaluation: auc:0.5758899760107212, precision:0.597213809812235, recall:0.5861546235472461, f1:0.5916325397896884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 143421.37it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 139890.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.250000\n",
      "Evaluation: auc:0.5821431516827531, precision:0.5817686250757117, recall:0.6008194414036844, f1:0.5911405843706244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142685.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.250000\n",
      "Evaluation: auc:0.5890135275832682, precision:0.5589036947304664, recall:0.6211399626407283, f1:0.5883806381164168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 142981.51it/s]\n",
      "100%|██████████| 2752512/2752512 [00:18<00:00, 154281.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.250000\n",
      "Evaluation: auc:0.5940610551265482, precision:0.5087825560266506, recall:0.64345627944387, f1:0.5682490825145022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2752512/2752512 [00:19<00:00, 139894.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Roxanne\\github\\cse258\\lightgcn.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(total\u001b[39m=\u001b[39mn_batches\u001b[39m*\u001b[39mbatch_size\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_batches):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     uij, _  \u001b[39m=\u001b[39m generate_train_batch(user_ratings_train, n_items, batch_size, train_users, test_ratings)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     users, items, labels \u001b[39m=\u001b[39m uij[:, \u001b[39m0\u001b[39m], uij[:, \u001b[39m1\u001b[39m], uij[:, \u001b[39m2\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     users, items, labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(users)\u001b[39m.\u001b[39mto(device), torch\u001b[39m.\u001b[39mtensor(items)\u001b[39m.\u001b[39mto(device), torch\u001b[39m.\u001b[39mtensor(labels)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;32md:\\Roxanne\\github\\cse258\\lightgcn.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     u \u001b[39m=\u001b[39m rd\u001b[39m.\u001b[39msample(train_users, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     i \u001b[39m=\u001b[39m rd\u001b[39m.\u001b[39;49msample(user_ratings_train[u], \u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     j \u001b[39m=\u001b[39m rd\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, n \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Roxanne/github/cse258/lightgcn.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# one negative sample\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Roxanne\\.conda\\envs\\py39\\lib\\random.py:427\u001b[0m, in \u001b[0;36mRandom.sample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Chooses k unique random elements from a population sequence or set.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mReturns a new list containing elements from the population while\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    401\u001b[0m \n\u001b[0;32m    402\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39m# Sampling without replacement entails tracking either potential\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[39m# selections (the pool) in a list or previous selections in a set.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m# too many calls to _randbelow(), making them slower and\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[39m# causing them to eat more entropy than necessary.\u001b[39;00m\n\u001b[1;32m--> 427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(population, _Set):\n\u001b[0;32m    428\u001b[0m     _warn(\u001b[39m'\u001b[39m\u001b[39mSampling from a set deprecated\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    429\u001b[0m           \u001b[39m'\u001b[39m\u001b[39msince Python 3.9 and will be removed in a subsequent version.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    430\u001b[0m           \u001b[39mDeprecationWarning\u001b[39;00m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    431\u001b[0m     population \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(population)\n",
      "File \u001b[1;32mc:\\Users\\Roxanne\\.conda\\envs\\py39\\lib\\abc.py:119\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mcls\u001b[39m, instance):\n\u001b[0;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m _abc_instancecheck(\u001b[39mcls\u001b[39;49m, instance)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "########################### START TRAINING & TESTING & EVALUATION#####################################\n",
    "model = LightGCN(n_users, n_items, 128, 4, info_norm_adj).to(device)\n",
    "opt = torch.optim.Adam(lr=lr, params=model.parameters(), weight_decay=0.001)\n",
    "# info_norm_adj = info_norm_adj.to(device)\n",
    "\n",
    "all_loss = []\n",
    "performance = []\n",
    "best_auc = 0\n",
    "best_precision = 0\n",
    "model_save_path = 'model/'\n",
    "pre_loss = 0\n",
    "for epoch in range(1, num_epoches+1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    n_batches = train_interacts // batch_size + 1\n",
    "    pbar = tqdm(total=n_batches*batch_size*2)\n",
    "    for i in range(n_batches):\n",
    "        uij, _  = generate_train_batch(user_ratings_train, n_items, batch_size, train_users, test_ratings)\n",
    "        users, items, labels = uij[:, 0], uij[:, 1], uij[:, 2]\n",
    "        users, items, labels = torch.tensor(users).to(device), torch.tensor(items).to(device), torch.tensor(labels).float().to(device)\n",
    "        predictions = model(users, items).float()\n",
    "        loss = model.loss(predictions, labels)\n",
    "        train_loss += loss.item()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        pbar.update(batch_size*2)\n",
    "    train_loss /= n_batches\n",
    "    all_loss.append(train_loss)\n",
    "    print(\"epoch {}, train loss: {:4f}\".format(epoch, train_loss))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_uij = generate_test_batch(user_ratings_train, user_ratings_test, n_items, train_users, test_ratings)\n",
    "        users, items, labels = t_uij[:, 0], t_uij[:, 1], t_uij[:, 2]\n",
    "        users, items = torch.tensor(users).to(device), torch.tensor(items).to(device)\n",
    "        pred = model(users, items)\n",
    "        pred = pred.cpu().numpy()\n",
    "        auc, precision, recall, f1score = evaluation(pred, labels)\n",
    "        performance.append([auc, precision, recall, f1score])\n",
    "        print(\"Evaluation: auc:{}, precision:{}, recall:{}, f1:{}\".format(auc, precision, recall, f1score)) \n",
    "        if auc > best_auc and train_loss < pre_loss:\n",
    "            best_auc = auc\n",
    "            best_precision = precision\n",
    "            state = {'net': model.state_dict(), 'opt':opt.state_dict(), 'epoch':epoch}\n",
    "            torch.save(state, model_save_path+f\"model_{epoch}.pth\")\n",
    "        pre_loss = train_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27727.746636,
   "end_time": "2022-05-30T13:23:12.996049",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-30T05:41:05.249413",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
